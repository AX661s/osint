"""
Investigate API åç«¯æ•°æ®å¤„ç†å™¨
åœ¨æœåŠ¡å™¨ç«¯å¤„ç†æµ·é‡æ•°æ®ï¼Œå‡è½»å‰ç«¯è´Ÿæ‹…
"""
import logging
from typing import Dict, Any, List, Set
from collections import defaultdict

logger = logging.getLogger(__name__)


class InvestigateDataProcessor:
    """
    Investigate API æ•°æ®å¤„ç†å™¨
    è´Ÿè´£æ•°æ®æ¸…æ´—ã€å»é‡ã€åˆå¹¶å’Œä¼˜åŒ–
    """
    
    def __init__(self, raw_data: Dict[str, Any]):
        self.raw_data = raw_data
        self.processed_data = None
    
    def process(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹
        """
        if not self.raw_data or 'data' not in self.raw_data:
            logger.error("âŒ [DataProcessor] Invalid raw data")
            return None
        
        data = self.raw_data['data']
        
        # é˜²å¾¡æ€§ç±»å‹æ£€æŸ¥ï¼šæŸäº›å“åº”ä¼šä»¥å­—ç¬¦ä¸²å ä½ï¼Œéœ€è½¬ä¸ºç©ºç»“æ„
        person_profile = data.get('person_profile', {})
        if not isinstance(person_profile, dict):
            logger.warning(f"âš ï¸ [DataProcessor] person_profile é dict ç±»å‹: {type(person_profile).__name__}ï¼Œå°†ä½¿ç”¨ç©ºå¯¹è±¡")
            person_profile = {}
        
        # å¦‚æœperson_profileä¸ºç©ºï¼Œå°è¯•ä»processedå­—æ®µè·å–
        if not person_profile or len(person_profile) == 0:
            processed = data.get('processed', {})
            if isinstance(processed, dict) and processed.get('identity'):
                logger.info(f"â„¹ï¸ [DataProcessor] ä½¿ç”¨processedæ•°æ®æ„å»ºperson_profile")
                # ä»processedé‡å»ºperson_profile
                person_profile = {
                    'primary_name': processed.get('identity', {}).get('primary_name', ''),
                    'name_variants': processed.get('identity', {}).get('name_variants', []),
                    'gender': processed.get('identity', {}).get('gender', ''),
                    'age': processed.get('identity', {}).get('age', 0),
                    'birthdate': processed.get('identity', {}).get('birthdate', ''),
                    'phones': processed.get('contacts', {}).get('phones', {}).get('all', []),
                    'emails': processed.get('contacts', {}).get('emails', {}).get('all', []),
                    'addresses': processed.get('geographic', {}).get('addresses', []),
                    'employment': processed.get('professional', {}).get('employment', []),
                    'education': processed.get('professional', {}).get('education', []),
                    'relatives': processed.get('network', {}).get('relatives', []),
                    'property_records': processed.get('financial', {}).get('properties', []),
                    'geolocation': processed.get('geographic', {}).get('geolocation', {}),
                    'account_registrations': [],
                    'sources': [],
                    'confidence_score': processed.get('quality', {}).get('overall_confidence', 0)
                }
        
        logger.info(f"ğŸ”„ [DataProcessor] å¼€å§‹å¤„ç†æ•°æ®...")
        
        self.processed_data = {
            # å…ƒæ•°æ®
            'meta': self._extract_metadata(data),
            
            # æ ¸å¿ƒèº«ä»½ï¼ˆå»é‡å§“åï¼‰
            'identity': self._process_identity(person_profile),
            
            # è”ç³»æ–¹å¼ï¼ˆæ·±åº¦å»é‡ï¼‰
            'contacts': self._process_contacts(person_profile),
            
            # èŒä¸šä¿¡æ¯ï¼ˆåˆå¹¶åŒå…¬å¸ï¼‰
            'professional': self._process_professional(person_profile),
            
            # ç¤¾äº¤åª’ä½“ï¼ˆæ™ºèƒ½åˆ†ç»„ï¼‰
            'social': self._process_social(person_profile),
            
            # åœ°ç†ä¿¡æ¯ï¼ˆåˆå¹¶åœ°å€ï¼‰
            'geographic': self._process_geographic(person_profile),
            
            # å…³ç³»ç½‘ç»œï¼ˆå»é‡ï¼‰
            'network': self._process_network(person_profile),
            
            # è´¢åŠ¡ä¿¡æ¯ï¼ˆå»é‡æˆ¿äº§ï¼‰
            'financial': self._process_financial(person_profile),
            
            # å®‰å…¨ä¿¡æ¯ï¼ˆåˆ†ç»„æ³„éœ²ï¼‰
            'security': self._process_security(person_profile),
            
            # æ•°æ®è´¨é‡
            'quality': self._calculate_quality(person_profile)
        }
        
        # è®¡ç®—å¤„ç†ç»Ÿè®¡
        stats = self._calculate_stats()
        logger.info(f"âœ… [DataProcessor] å¤„ç†å®Œæˆ: {stats}")
        
        return self.processed_data
    
    def _extract_metadata(self, data: Dict) -> Dict:
        """æå–å…ƒæ•°æ®"""
        return {
            'investigation_id': data.get('investigation_id', ''),
            'phone_number': data.get('phone_number', ''),
            'status': data.get('status', 'unknown'),
            'duration': data.get('duration_seconds', 0),
            'data_sources_count': data.get('data_sources_count', 0),
            'start_time': data.get('start_time', ''),
            'end_time': data.get('end_time', '')
        }
    
    def _process_identity(self, profile: Dict) -> Dict:
        """å¤„ç†èº«ä»½ä¿¡æ¯ - å»é‡å§“åå˜ä½“"""
        name_variants = profile.get('name_variants', [])
        unique_names = list(set(name_variants))  # å»é‡
        
        return {
            'primary_name': profile.get('primary_name', ''),
            'name_variants': unique_names,
            'name_count': len(unique_names),
            'gender': profile.get('gender', ''),
            'age': profile.get('age', 0),
            'birthdate': profile.get('birthdate', ''),
            'title_prefix': profile.get('title_prefix', ''),
            'middle_name': profile.get('middle_name', ''),
            'ethnicity': profile.get('ethnicity', ''),
            'religion': profile.get('religion', ''),
            'languages': list(set(profile.get('languages', []))),  # å»é‡è¯­è¨€
            'confidence_score': profile.get('confidence_score', 0)
        }
    
    def _process_contacts(self, profile: Dict) -> Dict:
        """å¤„ç†è”ç³»æ–¹å¼ - æ·±åº¦å»é‡å’Œåˆå¹¶"""
        phones = profile.get('phones', [])
        emails = profile.get('emails', [])
        
        # ç”µè¯å»é‡å’Œåˆå¹¶
        phone_map = {}
        for phone in phones:
            key = phone.get('number_e164')
            if not key:
                continue
            
            if key not in phone_map:
                phone_map[key] = {
                    'number': key,
                    'display': phone.get('display', key),
                    'type': phone.get('type', 'unknown'),
                    'carrier': phone.get('carrier', 'Unknown'),
                    'location': phone.get('location', ''),
                    'confidence': phone.get('confidence', 0),
                    'sources': set(phone.get('source', [])),
                    'last_seen': phone.get('last_seen')
                }
            else:
                # åˆå¹¶æ¥æº
                existing = phone_map[key]
                existing['sources'].update(phone.get('source', []))
                # æ›´æ–°ç½®ä¿¡åº¦ï¼ˆå–æœ€é«˜å€¼ï¼‰
                existing['confidence'] = max(existing['confidence'], phone.get('confidence', 0))
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        processed_phones = [
            {**p, 'sources': list(p['sources']), 'sources_count': len(p['sources'])}
            for p in phone_map.values()
        ]
        processed_phones.sort(key=lambda x: x['confidence'], reverse=True)
        
        # é‚®ç®±å»é‡å’Œåˆå¹¶
        email_map = {}
        for email in emails:
            key = (email.get('normalized') or email.get('address', '')).lower()
            if not key:
                continue
            
            if key not in email_map:
                email_map[key] = {
                    'address': email.get('address'),
                    'normalized': email.get('normalized', email.get('address')),
                    'type': email.get('type', 'unknown'),
                    'domain': email.get('domain', ''),
                    'confidence': email.get('confidence', 0),
                    'sources': set(email.get('source', [])),
                    'last_seen': email.get('last_seen')
                }
            else:
                # åˆå¹¶æ¥æº
                existing = email_map[key]
                existing['sources'].update(email.get('source', []))
                existing['confidence'] = max(existing['confidence'], email.get('confidence', 0))
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        processed_emails = [
            {**e, 'sources': list(e['sources']), 'sources_count': len(e['sources'])}
            for e in email_map.values()
        ]
        processed_emails.sort(key=lambda x: x['confidence'], reverse=True)
        
        return {
            'phones': {
                'all': processed_phones[:20],  # åªä¿ç•™å‰20ä¸ª
                'high_confidence': [p for p in processed_phones if p['confidence'] >= 0.8][:10],
                'total': len(processed_phones),
                'primary': processed_phones[0] if processed_phones else None
            },
            'emails': {
                'all': processed_emails[:25],  # åªä¿ç•™å‰25ä¸ª
                'high_confidence': [e for e in processed_emails if e['confidence'] >= 0.8][:15],
                'total': len(processed_emails),
                'primary': processed_emails[0] if processed_emails else None
            }
        }
    
    def _process_professional(self, profile: Dict) -> Dict:
        """å¤„ç†èŒä¸šä¿¡æ¯ - æŒ‰å…¬å¸åˆå¹¶"""
        employment = profile.get('employment', [])
        education = profile.get('education', [])
        
        # æŒ‰å…¬å¸åˆ†ç»„
        company_map = defaultdict(list)
        for job in employment:
            company = job.get('company', 'Unknown')
            company_map[company].append(job)
        
        # åˆå¹¶åŒå…¬å¸èŒä½
        consolidated = []
        for company, jobs in company_map.items():
            # æŒ‰å¼€å§‹æ—¥æœŸæ’åº
            jobs.sort(key=lambda j: j.get('start_date', '0000-00-00'), reverse=True)
            
            consolidated.append({
                'company': company,
                'positions': [
                    {
                        'title': j.get('title', 'Unknown'),
                        'start_date': j.get('start_date', ''),
                        'end_date': j.get('end_date', ''),
                        'location': j.get('location', ''),
                        'confidence': j.get('confidence', 0),
                        'source': j.get('source', '')
                    }
                    for j in jobs[:3]  # æ¯ä¸ªå…¬å¸æœ€å¤š3ä¸ªèŒä½
                ],
                'total_positions': len(jobs),
                'latest_position': jobs[0].get('title', '') if jobs else '',
                'confidence': max([j.get('confidence', 0) for j in jobs], default=0)
            })
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        consolidated.sort(key=lambda x: x['confidence'], reverse=True)
        
        return {
            'employment': consolidated[:15],  # æœ€å¤š15ä¸ªå…¬å¸
            'education': education[:10],
            'income_bracket': profile.get('income_bracket', ''),
            'total_companies': len(consolidated),
            'total_positions': len(employment)
        }
    
    def _process_social(self, profile: Dict) -> Dict:
        """å¤„ç†ç¤¾äº¤åª’ä½“ - æ™ºèƒ½åˆ†ç»„"""
        registrations = profile.get('account_registrations', [])
        
        # æŒ‰å¹³å°åˆ†ç»„
        platform_map = defaultdict(lambda: {
            'accounts': [],
            'emails': set(),
            'registration_dates': []
        })
        
        for account in registrations:
            platform = account.get('platform')
            if not platform:
                continue
            
            platform_data = platform_map[platform]
            platform_data['accounts'].append(account)
            if account.get('email'):
                platform_data['emails'].add(account['email'])
            if account.get('registration_date'):
                platform_data['registration_dates'].append(account['registration_date'])
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        platforms = []
        for platform_name, data in platform_map.items():
            platforms.append({
                'platform': platform_name,
                'account_count': len(data['accounts']),
                'unique_emails': list(data['emails']),
                'email_count': len(data['emails']),
                'earliest_registration': sorted(data['registration_dates'])[0] if data['registration_dates'] else '',
                'accounts': data['accounts'][:3]  # æ¯ä¸ªå¹³å°æœ€å¤š3ä¸ªè´¦æˆ·è¯¦æƒ…
            })
        
        # æŒ‰è´¦æˆ·æ•°é‡æ’åº
        platforms.sort(key=lambda x: x['account_count'], reverse=True)
        
        return {
            'platforms': platforms[:30],  # æœ€å¤š30ä¸ªå¹³å°
            'total_platforms': len(platforms),
            'total_accounts': len(registrations)
        }
    
    def _process_geographic(self, profile: Dict) -> Dict:
        """å¤„ç†åœ°ç†ä¿¡æ¯ - åˆå¹¶åœ°å€"""
        addresses = profile.get('addresses', [])
        geolocation = profile.get('geolocation', {})
        
        # åœ°å€å»é‡
        address_map = {}
        for addr in addresses:
            # åˆ›å»ºå”¯ä¸€é”®
            key = '|'.join([
                (addr.get('street') or '').lower().strip(),
                (addr.get('city') or '').lower().strip(),
                (addr.get('postal_code') or '').lower().strip()
            ])
            
            if not key or key == '||':
                continue
            
            if key not in address_map:
                address_map[key] = {
                    'street': addr.get('street', ''),
                    'city': addr.get('city', ''),
                    'state': addr.get('state', ''),
                    'postal_code': addr.get('postal_code', ''),
                    'country': addr.get('country', 'US'),
                    'role': addr.get('role', 'unknown'),
                    'confidence': addr.get('confidence', 0),
                    'sources': set(addr.get('source', [])),
                    'geolocation': addr.get('geolocation')
                }
            else:
                # åˆå¹¶æ¥æº
                existing = address_map[key]
                existing['sources'].update(addr.get('source', []))
                existing['confidence'] = max(existing['confidence'], addr.get('confidence', 0))
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        processed_addresses = [
            {**a, 'sources': list(a['sources']), 'sources_count': len(a['sources'])}
            for a in address_map.values()
        ]
        processed_addresses.sort(key=lambda x: x['confidence'], reverse=True)
        
        return {
            'addresses': processed_addresses[:15],  # æœ€å¤š15ä¸ªåœ°å€
            'total_addresses': len(processed_addresses),
            'current_address': processed_addresses[0] if processed_addresses else None,
            'geolocation': {
                'latitude': geolocation.get('latitude'),
                'longitude': geolocation.get('longitude'),
                'metro_area': geolocation.get('metro_area', ''),
                'region': geolocation.get('region', ''),
                'timezone': geolocation.get('timezone', ''),
                'precision': geolocation.get('precision', ''),
                'sources_count': geolocation.get('sources_count', 0)
            }
        }
    
    def _process_network(self, profile: Dict) -> Dict:
        """å¤„ç†å…³ç³»ç½‘ç»œ - å»é‡äº²å±"""
        relatives = profile.get('relatives', [])
        
        # äº²å±å»é‡ï¼ˆåŸºäºå§“åï¼‰
        relatives_map = {}
        for rel in relatives:
            name = (rel.get('name') or '').strip()
            if not name:
                continue
            
            if name not in relatives_map:
                relatives_map[name] = {
                    'name': name,
                    'relationship': rel.get('relationship', 'unknown'),
                    'confidence': rel.get('confidence', 0),
                    'sources': set(rel.get('sources', []))
                }
            else:
                # åˆå¹¶æ¥æº
                existing = relatives_map[name]
                existing['sources'].update(rel.get('sources', []))
                existing['confidence'] = max(existing['confidence'], rel.get('confidence', 0))
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        processed_relatives = [
            {**r, 'sources': list(r['sources']), 'sources_count': len(r['sources'])}
            for r in relatives_map.values()
        ]
        processed_relatives.sort(key=lambda x: x['confidence'], reverse=True)
        
        return {
            'relatives': processed_relatives[:20],  # æœ€å¤š20ä¸ªäº²å±
            'total_relatives': len(processed_relatives),
            'associates': profile.get('associates', [])[:10],
            'household_members': profile.get('household_members', [])[:10]
        }
    
    def _process_financial(self, profile: Dict) -> Dict:
        """å¤„ç†è´¢åŠ¡ä¿¡æ¯ - å»é‡æˆ¿äº§"""
        properties = profile.get('property_records', [])
        
        # æˆ¿äº§å»é‡
        property_map = {}
        for prop in properties:
            key = f"{prop.get('address', '')}_{prop.get('city', '')}_{prop.get('postal_code', '')}".lower()
            if not key or key == '__':
                continue
            
            if key not in property_map:
                property_map[key] = {
                    'address': prop.get('address', ''),
                    'city': prop.get('city', ''),
                    'state': prop.get('state', ''),
                    'postal_code': prop.get('postal_code', ''),
                    'purchase_year': prop.get('purchase_year'),
                    'built_year': prop.get('built_year'),
                    'estimated_value': prop.get('estimated_value', ''),
                    'bedrooms': prop.get('bedrooms', 0),
                    'bathrooms': prop.get('bathrooms', 0),
                    'square_feet': prop.get('square_feet', 0),
                    'property_type': prop.get('property_type', ''),
                    'sources': set(prop.get('sources', [])),
                    'confidence': prop.get('confidence', 0)
                }
            else:
                # åˆå¹¶æ¥æº
                existing = property_map[key]
                existing['sources'].update(prop.get('sources', []))
                existing['confidence'] = max(existing['confidence'], prop.get('confidence', 0))
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        processed_properties = [
            {**p, 'sources': list(p['sources']), 'sources_count': len(p['sources'])}
            for p in property_map.values()
        ]
        processed_properties.sort(key=lambda x: x.get('purchase_year') or 0, reverse=True)
        
        return {
            'properties': processed_properties[:15],  # æœ€å¤š15ä¸ªæˆ¿äº§
            'total_properties': len(processed_properties),
            'bank_affiliations': profile.get('bank_affiliations', []),
            'credit_capacity': profile.get('credit_capacity', {}),
            'income_bracket': profile.get('income_bracket', '')
        }
    
    def _process_security(self, profile: Dict) -> Dict:
        """å¤„ç†å®‰å…¨ä¿¡æ¯ - åˆ†ç»„æ³„éœ²æº"""
        leaked_credentials = profile.get('leaked_credentials', [])
        ip_history = profile.get('ip_history', [])
        
        # æŒ‰æ³„éœ²æºåˆ†ç»„
        leak_source_map = defaultdict(lambda: {
            'count': 0,
            'emails': set(),
            'leak_dates': [],
            'has_plaintext': False
        })
        
        for cred in leaked_credentials:
            source = cred.get('leak_source', 'Unknown')
            source_data = leak_source_map[source]
            source_data['count'] += 1
            if cred.get('email'):
                source_data['emails'].add(cred['email'])
            if cred.get('leak_date'):
                source_data['leak_dates'].append(cred['leak_date'])
            if cred.get('plaintext_available'):
                source_data['has_plaintext'] = True
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        leak_sources = [
            {
                'source': source,
                'count': data['count'],
                'emails': list(data['emails']),
                'email_count': len(data['emails']),
                'latest_leak': sorted(data['leak_dates'], reverse=True)[0] if data['leak_dates'] else '',
                'has_plaintext': data['has_plaintext']
            }
            for source, data in leak_source_map.items()
        ]
        leak_sources.sort(key=lambda x: x['count'], reverse=True)
        
        # IPå»é‡
        unique_ips = list(set([ip.get('ip') for ip in ip_history if ip.get('ip')]))
        
        return {
            'leaked_credentials': {
                'total': len(leaked_credentials),
                'sources': leak_sources[:20],  # æœ€å¤š20ä¸ªæ³„éœ²æº
                'total_sources': len(leak_sources),
                'has_plaintext': any(s['has_plaintext'] for s in leak_sources),
                'affected_emails': list(set([c.get('email') for c in leaked_credentials if c.get('email')]))
            },
            'ip_history': {
                'all': ip_history[:30],  # æœ€å¤š30ä¸ªIPè®°å½•
                'unique_ips': unique_ips[:20],
                'total': len(ip_history),
                'unique_count': len(unique_ips)
            },
            'ssn': profile.get('ssn'),
            'drivers_license': profile.get('drivers_license'),
            'passport_numbers': profile.get('passport_numbers', []),
            'national_id': profile.get('national_id', [])
        }
    
    def _calculate_quality(self, profile: Dict) -> Dict:
        """è®¡ç®—æ•°æ®è´¨é‡æŒ‡æ ‡"""
        field_confidences = profile.get('field_confidences', {})
        sources = profile.get('sources', [])
        
        # è®¡ç®—æ•°æ®å®Œæ•´æ€§
        completeness_fields = {
            'has_name': bool(profile.get('primary_name')),
            'has_age': bool(profile.get('age')),
            'has_gender': bool(profile.get('gender')),
            'has_phones': len(profile.get('phones', [])) > 0,
            'has_emails': len(profile.get('emails', [])) > 0,
            'has_addresses': len(profile.get('addresses', [])) > 0,
            'has_employment': len(profile.get('employment', [])) > 0,
            'has_education': len(profile.get('education', [])) > 0,
            'has_social': len(profile.get('account_registrations', [])) > 0,
            'has_relatives': len(profile.get('relatives', [])) > 0
        }
        
        filled_count = sum(completeness_fields.values())
        total_count = len(completeness_fields)
        completeness_percentage = round((filled_count / total_count) * 100) if total_count > 0 else 0
        
        return {
            'overall_confidence': profile.get('confidence_score', 0),
            'field_confidences': field_confidences,
            'completeness': {
                'percentage': completeness_percentage,
                'fields': completeness_fields,
                'filled_count': filled_count,
                'total_count': total_count
            },
            'sources_count': len(sources),
            'sources': sources[:50],  # åªä¿ç•™å‰50ä¸ªæ•°æ®æºåç§°
            'last_updated': profile.get('last_updated', '')
        }
    
    def _calculate_stats(self) -> str:
        """è®¡ç®—å¤„ç†ç»Ÿè®¡"""
        if not self.processed_data:
            return "No data processed"
        
        stats = []
        
        # è”ç³»æ–¹å¼ç»Ÿè®¡
        phones_total = self.processed_data['contacts']['phones']['total']
        phones_kept = len(self.processed_data['contacts']['phones']['all'])
        stats.append(f"ç”µè¯ {phones_kept}/{phones_total}")
        
        emails_total = self.processed_data['contacts']['emails']['total']
        emails_kept = len(self.processed_data['contacts']['emails']['all'])
        stats.append(f"é‚®ç®± {emails_kept}/{emails_total}")
        
        # èŒä¸šç»Ÿè®¡
        companies = len(self.processed_data['professional']['employment'])
        total_positions = self.processed_data['professional']['total_positions']
        stats.append(f"å…¬å¸ {companies} (èŒä½ {total_positions})")
        
        # ç¤¾äº¤åª’ä½“ç»Ÿè®¡
        platforms = len(self.processed_data['social']['platforms'])
        total_accounts = self.processed_data['social']['total_accounts']
        stats.append(f"å¹³å° {platforms} (è´¦æˆ· {total_accounts})")
        
        # åœ°å€ç»Ÿè®¡
        addresses = len(self.processed_data['geographic']['addresses'])
        total_addresses = self.processed_data['geographic']['total_addresses']
        stats.append(f"åœ°å€ {addresses}/{total_addresses}")
        
        return ", ".join(stats)
    
    def get_processed(self) -> Dict[str, Any]:
        """è·å–å¤„ç†åçš„æ•°æ®"""
        if not self.processed_data:
            self.process()
        return self.processed_data
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ•°æ®æ‘˜è¦ï¼ˆç”¨äºå¿«é€Ÿé¢„è§ˆï¼‰"""
        if not self.processed_data:
            result = self.process()
            if not result:
                logger.error("âŒ [DataProcessor] æ— æ³•ç”Ÿæˆæ‘˜è¦ï¼šæ•°æ®å¤„ç†å¤±è´¥")
                return None
        
        # å®‰å…¨åœ°è®¿é—®åµŒå¥—å­—å…¸
        try:
            return {
                'identity': {
                    'name': self.processed_data.get('identity', {}).get('primary_name', ''),
                    'age': self.processed_data.get('identity', {}).get('age', 0),
                    'gender': self.processed_data.get('identity', {}).get('gender', ''),
                    'location': self.processed_data.get('geographic', {}).get('geolocation', {}).get('metro_area', '')
                },
                'stats': {
                    'phones': self.processed_data.get('contacts', {}).get('phones', {}).get('total', 0),
                    'emails': self.processed_data.get('contacts', {}).get('emails', {}).get('total', 0),
                    'companies': self.processed_data.get('professional', {}).get('total_companies', 0),
                    'platforms': self.processed_data.get('social', {}).get('total_platforms', 0),
                    'addresses': self.processed_data.get('geographic', {}).get('total_addresses', 0),
                    'relatives': self.processed_data.get('network', {}).get('total_relatives', 0),
                    'properties': self.processed_data.get('financial', {}).get('total_properties', 0),
                    'leaks': self.processed_data.get('security', {}).get('leaked_credentials', {}).get('total', 0),
                    'data_sources': self.processed_data.get('meta', {}).get('data_sources_count', 0),
                    'confidence': round(self.processed_data.get('quality', {}).get('overall_confidence', 0) * 100)
                },
                'highlights': {
                    'primary_phone': self.processed_data.get('contacts', {}).get('phones', {}).get('primary'),
                    'primary_email': self.processed_data.get('contacts', {}).get('emails', {}).get('primary'),
                    'current_address': self.processed_data.get('geographic', {}).get('current_address'),
                    'latest_job': self.processed_data.get('professional', {}).get('employment', [None])[0] if self.processed_data.get('professional', {}).get('employment') else None
                },
                'risks': {
                    'has_leaks': self.processed_data.get('security', {}).get('leaked_credentials', {}).get('total', 0) > 0,
                    'leak_count': self.processed_data.get('security', {}).get('leaked_credentials', {}).get('total', 0),
                    'has_plaintext': self.processed_data.get('security', {}).get('leaked_credentials', {}).get('has_plaintext', False)
                }
            }
        except Exception as e:
            logger.error(f"âŒ [DataProcessor] æ‘˜è¦ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            return None


def process_investigate_response(raw_response: Dict[str, Any]) -> Dict[str, Any]:
    """
    å¿«é€Ÿå¤„ç†å‡½æ•° - å¤„ç† Investigate API å“åº”
    
    Args:
        raw_response: Investigate API çš„åŸå§‹å“åº”
        
    Returns:
        å¤„ç†åçš„ç»“æ„åŒ–æ•°æ®
    """
    try:
        processor = InvestigateDataProcessor(raw_response)
        processed = processor.process()
        
        if not processed:
            logger.error("âŒ [DataProcessor] æ•°æ®å¤„ç†å¤±è´¥")
            return None
        
        logger.info(f"âœ… [DataProcessor] æ•°æ®å¤„ç†æˆåŠŸ")
        return processed
        
    except Exception as e:
        logger.error(f"âŒ [DataProcessor] å¤„ç†å¼‚å¸¸: {str(e)}")
        return None


def get_investigate_summary(raw_response: Dict[str, Any]) -> Dict[str, Any]:
    """
    è·å–æ•°æ®æ‘˜è¦ - ç”¨äºå¿«é€Ÿé¢„è§ˆ
    
    Args:
        raw_response: Investigate API çš„åŸå§‹å“åº”
        
    Returns:
        æ•°æ®æ‘˜è¦
    """
    try:
        processor = InvestigateDataProcessor(raw_response)
        return processor.get_summary()
    except Exception as e:
        logger.error(f"âŒ [DataProcessor] æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None
