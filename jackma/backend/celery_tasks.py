"""
Celeryå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
å¤„ç†è€—æ—¶çš„OSINTæŸ¥è¯¢ä»»åŠ¡
"""
from celery import Celery, Task
from celery.result import AsyncResult
import logging
import os
from typing import Dict, Any
import json
from datetime import datetime

logger = logging.getLogger(__name__)

# Celeryé…ç½®
REDIS_URL = os.environ.get('REDIS_URL', 'redis://localhost:6379')
CELERY_BROKER_URL = f"{REDIS_URL}/0"  # Redis DB 0 ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—
CELERY_RESULT_BACKEND = f"{REDIS_URL}/1"  # Redis DB 1 å­˜å‚¨ä»»åŠ¡ç»“æœ

# åˆ›å»ºCeleryåº”ç”¨
celery_app = Celery(
    'osint_tracker',
    broker=CELERY_BROKER_URL,
    backend=CELERY_RESULT_BACKEND
)

# Celeryé…ç½®
celery_app.conf.update(
    # ä»»åŠ¡åºåˆ—åŒ–
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    
    # ä»»åŠ¡ç»“æœé…ç½®
    result_expires=3600,  # ç»“æœä¿ç•™1å°æ—¶
    result_backend_transport_options={
        'master_name': 'mymaster',
        'visibility_timeout': 3600,
    },
    
    # ä»»åŠ¡æ‰§è¡Œé…ç½®
    task_acks_late=True,  # ä»»åŠ¡å®Œæˆåæ‰ç¡®è®¤
    task_reject_on_worker_lost=True,  # Workerä¸¢å¤±æ—¶æ‹’ç»ä»»åŠ¡
    task_time_limit=300,  # ä»»åŠ¡æœ€å¤§æ‰§è¡Œæ—¶é—´5åˆ†é’Ÿ
    task_soft_time_limit=240,  # è½¯è¶…æ—¶4åˆ†é’Ÿ
    
    # Workeré…ç½®
    worker_prefetch_multiplier=1,  # æ¯æ¬¡åªé¢„å–1ä¸ªä»»åŠ¡
    worker_max_tasks_per_child=100,  # æ¯ä¸ªworkeræœ€å¤šæ‰§è¡Œ100ä¸ªä»»åŠ¡åé‡å¯
    
    # é‡è¯•é…ç½®
    task_default_retry_delay=60,  # é»˜è®¤é‡è¯•å»¶è¿Ÿ60ç§’
    task_max_retries=3,  # æœ€å¤šé‡è¯•3æ¬¡
)


class CallbackTask(Task):
    """å¸¦å›è°ƒçš„ä»»åŠ¡åŸºç±»"""
    
    def on_success(self, retval, task_id, args, kwargs):
        """ä»»åŠ¡æˆåŠŸæ—¶çš„å›è°ƒ"""
        logger.info(f"âœ… ä»»åŠ¡æˆåŠŸ: {task_id}")
    
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """ä»»åŠ¡å¤±è´¥æ—¶çš„å›è°ƒ"""
        logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(exc)}")
    
    def on_retry(self, exc, task_id, args, kwargs, einfo):
        """ä»»åŠ¡é‡è¯•æ—¶çš„å›è°ƒ"""
        logger.warning(f"âš ï¸ ä»»åŠ¡é‡è¯•: {task_id}, åŸå› : {str(exc)}")


@celery_app.task(
    bind=True,
    base=CallbackTask,
    name='osint_tracker.query_phone',
    max_retries=3,
    default_retry_delay=60
)
def async_query_phone(self, phone: str, timeout: int = 120) -> Dict[str, Any]:
    """
    å¼‚æ­¥æ‰§è¡Œæ‰‹æœºå·æŸ¥è¯¢
    
    Args:
        phone: æ‰‹æœºå·
        timeout: è¶…æ—¶æ—¶é—´
    
    Returns:
        æŸ¥è¯¢ç»“æœå­—å…¸
    """
    try:
        logger.info(f"ğŸ” å¼€å§‹å¼‚æ­¥æŸ¥è¯¢æ‰‹æœºå·: {phone}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROCESSING',
            meta={
                'phone': phone,
                'status': 'Querying external APIs...',
                'progress': 10
            }
        )
        
        # å¯¼å…¥æŸ¥è¯¢å‡½æ•°ï¼ˆå»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–ï¼‰
        import asyncio
        from apis import query_phone_comprehensive
        
        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œå¼‚æ­¥æŸ¥è¯¢
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            result = loop.run_until_complete(query_phone_comprehensive(phone))
            result_dict = result.model_dump() if hasattr(result, 'model_dump') else result
        finally:
            loop.close()
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROCESSING',
            meta={
                'phone': phone,
                'status': 'Saving results...',
                'progress': 80
            }
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“å’Œç¼“å­˜
        from models import SessionLocal
        from db_operations import save_phone_query
        from redis_cache import save_cached_result
        
        db_session = SessionLocal()
        try:
            # ä¿å­˜åˆ°æ•°æ®åº“
            success = result_dict.get('success', False)
            error_msg = result_dict.get('error', None)
            save_phone_query(
                db=db_session,
                phone=phone,
                result=result_dict,
                success=success,
                error=error_msg
            )
            
            # ä¿å­˜åˆ°Redisç¼“å­˜
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(
                    save_cached_result(phone, "phone", result_dict, db_session)
                )
            finally:
                loop.close()
            
        finally:
            db_session.close()
        
        logger.info(f"âœ… æ‰‹æœºå·æŸ¥è¯¢å®Œæˆ: {phone}")
        
        return {
            'success': True,
            'phone': phone,
            'data': result_dict,
            'completed_at': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ æ‰‹æœºå·æŸ¥è¯¢å¤±è´¥: {phone}, é”™è¯¯: {error_msg}")
        
        # é‡è¯•é€»è¾‘
        if self.request.retries < self.max_retries:
            logger.info(f"âš ï¸ å‡†å¤‡é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
            raise self.retry(exc=e, countdown=60)
        
        # æœ€ç»ˆå¤±è´¥ï¼Œè¿”å›é”™è¯¯ç»“æœ
        return {
            'success': False,
            'phone': phone,
            'error': error_msg,
            'completed_at': datetime.utcnow().isoformat()
        }


@celery_app.task(
    bind=True,
    base=CallbackTask,
    name='osint_tracker.query_email',
    max_retries=3,
    default_retry_delay=60
)
def async_query_email(self, email: str, timeout: int = 120) -> Dict[str, Any]:
    """
    å¼‚æ­¥æ‰§è¡Œé‚®ç®±æŸ¥è¯¢
    
    Args:
        email: é‚®ç®±åœ°å€
        timeout: è¶…æ—¶æ—¶é—´
    
    Returns:
        æŸ¥è¯¢ç»“æœå­—å…¸
    """
    try:
        logger.info(f"ğŸ“§ å¼€å§‹å¼‚æ­¥æŸ¥è¯¢é‚®ç®±: {email}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROCESSING',
            meta={
                'email': email,
                'status': 'Querying external APIs...',
                'progress': 10
            }
        )
        
        # å¯¼å…¥æŸ¥è¯¢å‡½æ•°
        import asyncio
        from apis import query_email_comprehensive
        
        # æ‰§è¡Œå¼‚æ­¥æŸ¥è¯¢
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            result = loop.run_until_complete(query_email_comprehensive(email))
            result_dict = result.model_dump() if hasattr(result, 'model_dump') else result
        finally:
            loop.close()
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROCESSING',
            meta={
                'email': email,
                'status': 'Saving results...',
                'progress': 80
            }
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“å’Œç¼“å­˜
        from models import SessionLocal
        from db_operations import save_email_query
        from redis_cache import save_cached_result
        
        db_session = SessionLocal()
        try:
            # ä¿å­˜åˆ°æ•°æ®åº“
            success = result_dict.get('success', False)
            error_msg = result_dict.get('error', None)
            save_email_query(
                db=db_session,
                email=email,
                result=result_dict,
                success=success,
                error=error_msg
            )
            
            # ä¿å­˜åˆ°Redisç¼“å­˜
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(
                    save_cached_result(email, "email", result_dict, db_session)
                )
            finally:
                loop.close()
            
        finally:
            db_session.close()
        
        logger.info(f"âœ… é‚®ç®±æŸ¥è¯¢å®Œæˆ: {email}")
        
        return {
            'success': True,
            'email': email,
            'data': result_dict,
            'completed_at': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"âŒ é‚®ç®±æŸ¥è¯¢å¤±è´¥: {email}, é”™è¯¯: {error_msg}")
        
        # é‡è¯•é€»è¾‘
        if self.request.retries < self.max_retries:
            logger.info(f"âš ï¸ å‡†å¤‡é‡è¯• ({self.request.retries + 1}/{self.max_retries})")
            raise self.retry(exc=e, countdown=60)
        
        # æœ€ç»ˆå¤±è´¥
        return {
            'success': False,
            'email': email,
            'error': error_msg,
            'completed_at': datetime.utcnow().isoformat()
        }


@celery_app.task(name='osint_tracker.cleanup_old_results')
def cleanup_old_results():
    """
    å®šæœŸæ¸…ç†è¿‡æœŸçš„ä»»åŠ¡ç»“æœ
    """
    try:
        from celery.result import AsyncResult
        # æ¸…ç†é€»è¾‘
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸä»»åŠ¡ç»“æœ")
        # å®ç°æ¸…ç†é€»è¾‘
        logger.info("âœ… æ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†å¤±è´¥: {str(e)}")


# å®šæœŸä»»åŠ¡é…ç½®
celery_app.conf.beat_schedule = {
    'cleanup-every-hour': {
        'task': 'osint_tracker.cleanup_old_results',
        'schedule': 3600.0,  # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
    },
}


def get_task_status(task_id: str) -> Dict[str, Any]:
    """
    è·å–ä»»åŠ¡çŠ¶æ€
    
    Args:
        task_id: ä»»åŠ¡ID
    
    Returns:
        ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
    """
    try:
        task = AsyncResult(task_id, app=celery_app)
        
        if task.state == 'PENDING':
            return {
                'task_id': task_id,
                'state': 'PENDING',
                'status': 'Task is waiting in queue...',
                'progress': 0
            }
        elif task.state == 'PROCESSING':
            return {
                'task_id': task_id,
                'state': 'PROCESSING',
                'status': task.info.get('status', 'Processing...'),
                'progress': task.info.get('progress', 50)
            }
        elif task.state == 'SUCCESS':
            return {
                'task_id': task_id,
                'state': 'SUCCESS',
                'status': 'Task completed successfully',
                'progress': 100,
                'result': task.result
            }
        elif task.state == 'FAILURE':
            return {
                'task_id': task_id,
                'state': 'FAILURE',
                'status': 'Task failed',
                'progress': 0,
                'error': str(task.info)
            }
        elif task.state == 'RETRY':
            return {
                'task_id': task_id,
                'state': 'RETRY',
                'status': 'Task is being retried...',
                'progress': 25
            }
        else:
            return {
                'task_id': task_id,
                'state': task.state,
                'status': 'Unknown state',
                'progress': 0
            }
    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        return {
            'task_id': task_id,
            'state': 'ERROR',
            'status': 'Failed to get task status',
            'error': str(e)
        }


def cancel_task(task_id: str) -> bool:
    """
    å–æ¶ˆä»»åŠ¡
    
    Args:
        task_id: ä»»åŠ¡ID
    
    Returns:
        æ˜¯å¦å–æ¶ˆæˆåŠŸ
    """
    try:
        task = AsyncResult(task_id, app=celery_app)
        task.revoke(terminate=True)
        logger.info(f"âœ… ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")
        return True
    except Exception as e:
        logger.error(f"âŒ å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")
        return False


def get_queue_stats() -> Dict[str, Any]:
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        é˜Ÿåˆ—ç»Ÿè®¡æ•°æ®
    """
    try:
        inspect = celery_app.control.inspect()
        
        # è·å–æ´»è·ƒä»»åŠ¡
        active = inspect.active()
        active_count = sum(len(tasks) for tasks in (active or {}).values())
        
        # è·å–é¢„å®šä»»åŠ¡
        scheduled = inspect.scheduled()
        scheduled_count = sum(len(tasks) for tasks in (scheduled or {}).values())
        
        # è·å–ä¿ç•™ä»»åŠ¡
        reserved = inspect.reserved()
        reserved_count = sum(len(tasks) for tasks in (reserved or {}).values())
        
        return {
            'active_tasks': active_count,
            'scheduled_tasks': scheduled_count,
            'reserved_tasks': reserved_count,
            'total_pending': active_count + scheduled_count + reserved_count
        }
    except Exception as e:
        logger.error(f"âŒ è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")
        return {
            'error': str(e)
        }


